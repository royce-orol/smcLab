{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB EXERCISE - 1 - IMDB MOVIE REVIEWS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various NLP preprocessing tasks\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "from nltk.wsd import lesk\n",
    "from nltk.chunk import ne_chunk\n",
    "from nltk.tree import Tree\n",
    "\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation and numbers\n",
    "df['num_review'] = df['html_review'].apply(lambda x: re.sub(\"[^a-zA-Z.]\", \" \", x))\n",
    "#df['num_review'] = df['html_review'].apply(lambda x: re.sub(\"[^a-zA-Z.]\", \" \", x)) not removing .\n",
    "\n",
    "print(\"Original Review:\\n\", df['html_review'].iloc[0])\n",
    "print(\"\\nCleaned (No punctuation/numbers):\\n\", df['num_review'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to lowercase to ensure uniformity and to facilitate case-insensitive comparisons.\n",
    "df['low_review'] = df['num_review'].apply(lambda x: BeautifulSoup(x, \"html.parser\").get_text().lower())\n",
    "print(df['low_review'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence Segmentation\n",
    "df['sentences'] = df['low_review'].apply(lambda x: sent_tokenize(x))\n",
    "print(df['sentences'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "df['tokens'] = df['sentences'].apply(lambda x: word_tokenize(\" \".join(x)))\n",
    "print(df['tokens'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Word Removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df['tokens_no_stopwords'] = df['tokens'].apply(lambda x: [t for t in x if t not in stop_words and t not in string.punctuation])\n",
    "\n",
    "print(df['tokens_no_stopwords'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "df['stemmed_tokens'] = df['tokens_no_stopwords'].apply(lambda tokens: [stemmer.stem(t) for t in tokens])\n",
    "print(df['stemmed_tokens'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part-of-Speech Tagging\n",
    "df['pos_tags'] = df['tokens_no_stopwords'].apply(pos_tag)\n",
    "print(df['pos_tags'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Sense Disambiguation\n",
    "target_word = 'movie'\n",
    "\n",
    "# Apply Lesk WSD across all reviews\n",
    "df[f'{target_word}_sense'] = df['tokens_no_stopwords'].apply(\n",
    "    lambda tokens: lesk(tokens, target_word).definition() if target_word in tokens and lesk(tokens, target_word) else 'No sense'\n",
    ")\n",
    "\n",
    "# Example output\n",
    "print(df[[f'{target_word}_sense']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Named Entity Recognition\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# NER using spacy\n",
    "def spacy_ner(text):\n",
    "    doc = nlp(text)\n",
    "    return [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "df['named_entities'] = df['html_review'].apply(spacy_ner)\n",
    "print(df['named_entities'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordCloud\n",
    "text = \" \".join(review for review in df['html_review'])\n",
    "wordcloud = WordCloud(stopwords=STOPWORDS, background_color=\"white\").generate(text)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
